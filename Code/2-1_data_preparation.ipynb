{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# II) Classification et explication des données\n",
    "\n",
    "## 1) Classification des données\n",
    "\n",
    "Nous allons maintenant utiliser les données pour faire de la classification et de l'explication. Nous allons utiliser les données de la base de données Image Net qui contient des images de différents animaux.\n",
    "\n",
    "Pour réaliser cette tâche, nous allons utiliser une ensemble d'image issue de la base de données Image Net. Nous allons utiliser les images de 6 classes différentes. Pour chaque classe, nous avons 99% images d'entrainement et 1% images de test. Les classes sont les suivantes :\n",
    "\n",
    "- n02114367 (loup)\n",
    "- n01484850 (requin)\n",
    "- n01614925 (aigle)\n",
    "- n02133161 (ours)\n",
    "- n01537544 (passerin indigo)\n",
    "- n01443537 (poisson rouge)\n",
    "\n",
    "Nous allons utiliser les images d'entrainement pour entrainer un modèle de classification et les images de test pour évaluer la performance du modèle. Nous allons ensuite utiliser les images de test pour expliquer les prédictions du modèle.\n",
    "\n",
    "Nous allons diviser notre travail différentes parties :\n",
    "\n",
    "1) Récupérer les données sur Kaggle et sélectionner les images des classes qui nous intéressent (https://www.kaggle.com/c/imagenet-object-localization-challenge)\n",
    "2) Traiter les données, cela implique de les diviser en classe égale et de les redimensionner, pour ce faire, nous pourrons utiliser des bibliothèques comme OpenCV ou Pillow\n",
    "3) Diviser les données en données d'entrainement et données de test\n",
    "4) Le choix du modèle de classification : nous utiliserons des modèles couramment utilisés pour la classification d'images incluent les réseaux de neurones convolutionnels (CNN), qui ont obtenu de bons résultats dans de nombreux domaines.\n",
    "5) Entrainer un modèle de classification, pour ce faire, nous pourrons utiliser des bibliothèques comme Keras ou PyTorch ou TensorFlow\n",
    "6) Évaluer la performance du modèle sur les données de test, et obtenir l'accuarcy du modèle\n",
    "7) Utiliser les images de test pour expliquer les prédictions du modèle, pour ce faire, nous pourrons utiliser des bibliothèques comme LIME ou SHAP\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-27T15:51:23.016200Z",
     "start_time": "2023-05-27T15:51:23.006647Z"
    }
   },
   "outputs": [],
   "source": [
    "# Importer les bibliothèques nécessaires\n",
    "import os\n",
    "import shutil\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Nous listons l'ensemble des noms de dossiers, où se trouvent les images qui nous intéressent."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-27T15:51:23.016439Z",
     "start_time": "2023-05-27T15:51:23.011571Z"
    }
   },
   "outputs": [],
   "source": [
    "# Définir les classes qui nous intéressent\n",
    "classes_names = {'n02114367': 'loup', 'n01484850': 'requin', 'n01614925': 'aigle', 'n02133161': 'ours',\n",
    "                 'n01537544': 'passerin indigo', 'n01443537': 'poisson rouge'}\n",
    "classes = list(classes_names.keys())\n",
    "\n",
    "# Définir le chemin vers les données\n",
    "data_path = './ILSVRC/Data/CLS-LOC/train'"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Création du dossier `data` pour stocker les images."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-27T15:51:23.022189Z",
     "start_time": "2023-05-27T15:51:23.015193Z"
    }
   },
   "outputs": [],
   "source": [
    "# Créer un dossier pour stocker les images des classes qui nous intéressent\n",
    "os.makedirs('./data', exist_ok=True)\n",
    "for c in classes:\n",
    "    os.makedirs('./data/' + c, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Nous récupérons seulement les images des dossiers que nous enregistrons dans `./data/id_dossier_animal`."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-27T15:52:45.727920Z",
     "start_time": "2023-05-27T15:51:23.020292Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nombre d'images invalides: 5\r"
     ]
    }
   ],
   "source": [
    "from PIL import UnidentifiedImageError\n",
    "\n",
    "# Copier 1200 images par classes qui nous intéressent dans le dossier que nous venons de créer\n",
    "\n",
    "taille_data = 1200\n",
    "inv = 0\n",
    "for c in classes:\n",
    "    files = os.listdir(os.path.join(data_path, c))\n",
    "    for f in files[:taille_data]:\n",
    "        # Vérifier si le fichier est un fichier d'image valide\n",
    "        try:\n",
    "            im = Image.open(os.path.join(data_path, c, f))\n",
    "            im.verify()\n",
    "            shutil.copy(os.path.join(data_path, c, f), os.path.join('./data', c, f))\n",
    "            im = Image.open(os.path.join('./data', c, f))\n",
    "            im.save(os.path.join('./data', c, f))\n",
    "        except (IOError, SyntaxError, UnidentifiedImageError) as e:\n",
    "            inv += 1\n",
    "            print(\"Nombre d'images invalides:\", inv, end=\"\\r\")"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Nous divisons notre dataset à 95% (au lieu de 99% pour avoir une évaluation plus précise) donc 95% des images chaque dossier (tiré aléatoirement) sont mise dans le fichier `./data/train` et 5% dans `./data/test`."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-27T15:52:49.407492Z",
     "start_time": "2023-05-27T15:52:45.730087Z"
    }
   },
   "outputs": [],
   "source": [
    "# Diviser les données en données d'entrainement et données de test\n",
    "# Nous allons utiliser 95% des données pour l'entrainement et 5% pour le test\n",
    "# Nous allons stocker les données d'entrainement dans un dossier train et les données de test dans un dossier test\n",
    "\n",
    "# Créer les dossiers train et test\n",
    "for c in classes:\n",
    "    os.makedirs('./data/train/' + c, exist_ok=True)\n",
    "    os.makedirs('./data/test/' + c, exist_ok=True)\n",
    "\n",
    "pourcentage_train = 0.95\n",
    "\n",
    "os.makedirs('./data/train', exist_ok=True)\n",
    "os.makedirs('./data/test', exist_ok=True)\n",
    "\n",
    "for c in classes:\n",
    "    files = os.listdir(os.path.join('./data', c))\n",
    "    for f in files[:round(pourcentage_train * len(files)) - 1]:\n",
    "        shutil.copy(os.path.join('./data', c, f), os.path.join('./data/train', c, f))\n",
    "    for f in files[round(pourcentage_train * len(files)) - 1:]:\n",
    "        shutil.copy(os.path.join('./data', c, f), os.path.join('./data/test', c, f))"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Nous venons de mettre l'ensemble des images dans les bons dossiers, ceux pour l'entrainement et ceux pour l'évaluation.\n",
    "Maintenant entrainons notre modèle [2-2_cnn_model](./2-2_cnn_model.ipynb)."
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
